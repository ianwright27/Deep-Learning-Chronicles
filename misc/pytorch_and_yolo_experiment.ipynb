{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc328c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel GPU (XPU) available: False\n",
      "Intel GPU not detected. Ensure your Intel Graphics drivers are up to date.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Check if the Intel XPU backend is available\n",
    "xpu_available = torch.xpu.is_available()\n",
    "print(f\"Intel GPU (XPU) available: {xpu_available}\")\n",
    "\n",
    "if xpu_available:\n",
    "    # 2. Get the specific name of your Intel GPU\n",
    "    device_name = torch.xpu.get_device_name(0)\n",
    "    print(f\"Device Name: {device_name}\")\n",
    "    \n",
    "    # 3. Create a small tensor and move it to the Intel GPU\n",
    "    device = torch.device(\"xpu\")\n",
    "    x = torch.randn(3, 3).to(device)\n",
    "    \n",
    "    # 4. Perform a small calculation to confirm it works\n",
    "    y = x * x\n",
    "    print(\"\\nCalculation successful!\")\n",
    "    print(f\"Tensor is currently on: {y.device}\")\n",
    "else:\n",
    "    print(\"Intel GPU not detected. Ensure your Intel Graphics drivers are up to date.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b422f5",
   "metadata": {},
   "source": [
    "Now let's see YOLO OpenVINNO export\n",
    "How it compares to regular cpu inference speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c60bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Running inference with the original model...\n",
      "\n",
      "Found https://thumbs.dreamstime.com/b/cute-cat-sleeping-street-car-random-58655731.jpg locally at cute-cat-sleeping-street-car-random-58655731.jpg\n",
      "image 1/1 C:\\Users\\ianwr\\cute-cat-sleeping-street-car-random-58655731.jpg: 480x640 1 cat, 95.7ms\n",
      "Speed: 4.6ms preprocess, 95.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "====================\n",
      "Running inference with the OpenVINO model...\n",
      "Loading yolo11n_openvino_model/ for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference on (CPU)...\n",
      "\n",
      "Found https://thumbs.dreamstime.com/b/cute-cat-sleeping-street-car-random-58655731.jpg locally at cute-cat-sleeping-street-car-random-58655731.jpg\n",
      "image 1/1 C:\\Users\\ianwr\\cute-cat-sleeping-street-car-random-58655731.jpg: 640x640 1 car, 1 cat, 202.5ms\n",
      "Speed: 3.8ms preprocess, 202.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLO model\n",
    "# model = YOLO('yolov8n.pt')\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# Export the model to OpenVINO format\n",
    "# model.export(format='openvino') # creates 'yolo11n_openvino_model/'\n",
    "\n",
    "# Load the exported OpenVINO model\n",
    "ov_model = YOLO('yolo11n_openvino_model/')\n",
    "\n",
    "# image_url = \"https://c8.alamy.com/comp/P6YB2N/los-angeles-usa-june-29-unidentified-random-people-in-the-streets-of-downtown-of-los-angeles-ca-on-june-29-2018-P6YB2N.jpg\"\n",
    "image_url = \"https://thumbs.dreamstime.com/b/cute-cat-sleeping-street-car-random-58655731.jpg\"\n",
    "# run inference on an image (original model)\n",
    "print(\"Running inference with the original model...\")\n",
    "results = model.predict(source=image_url)\n",
    "\n",
    "print(\"=\"*20)\n",
    "\n",
    "# run inference on an image (openvino model)\n",
    "print(\"Running inference with the OpenVINO model...\")\n",
    "results = ov_model.predict(source=image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050f9215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶á Bat-vision online. Press Q to quit.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ---- CONFIG ----\n",
    "STREAM_URL = \"http://192.168.0.15:4747/video\" # coming from my DroidCAM app on Android (substitute for Live Camera)\n",
    "MODEL_PATH = \"yolo11n.pt\"   # change to -seg or -pose if needed\n",
    "CONF_THRESH = 0.5\n",
    "\n",
    "# ---- LOAD MODEL ----\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# ---- OPEN STREAM ----\n",
    "cap = cv2.VideoCapture(STREAM_URL)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"‚ùå Could not open DroidCAM stream\")\n",
    "\n",
    "# Optional: reduce latency\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)\n",
    "\n",
    "print(\"ü¶á Bat-vision online. Press Q to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # Run inference\n",
    "    results = model(frame, conf=CONF_THRESH, verbose=False)\n",
    "\n",
    "    # Draw results\n",
    "    annotated = results[0].plot()\n",
    "\n",
    "    cv2.imshow(\"YOLO DroidCAM\", annotated)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf5f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
